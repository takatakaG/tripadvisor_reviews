{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import MeCab as mc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "import matplotlib.pyplot as pyp\n",
    "from sklearn.linear_model import RidgeCV,LassoCV,ElasticNetCV,RidgeClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL取得作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url():    \n",
    "    browser = webdriver.Chrome(executable_path=\"/Users/shimizutakashibun/chromedriver\")\n",
    "    #スタートページ\n",
    "    browser.get(\"https://www.tripadvisor.jp/Attractions-g1021202-Activities-Tomioka_Gunma_Prefecture_Kanto.html\")\n",
    "    df = pd.DataFrame()\n",
    "    posts=browser.find_elements_by_css_selector('div.attractions-attraction-overview-main-PoiInfo__info--260v8')\n",
    "    for post in posts:\n",
    "        pre1_url = post.find_element_by_css_selector('div:nth-child(1)')\n",
    "        pre2_url = pre1_url.find_element_by_css_selector('div:nth-child(2)')\n",
    "        url = pre2_url.find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "        se = pd.Series([url], ['url'])\n",
    "        df = df.append(se, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url = get_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url[\"url\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各URLのタイトル・コメント・スコアの抽出作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details():\n",
    "    details_df = pd.DataFrame()\n",
    "    for i in range(len(df_url.index)): \n",
    "        print(\"getting info of {}\".format(df_url.loc[i].url))\n",
    "        browser = webdriver.Chrome(executable_path=\"/Users/shimizutakashibun/chromedriver\")\n",
    "        browser.get(df_url.loc[i].url)\n",
    "        page=0\n",
    "\n",
    "        try:\n",
    "\n",
    "            while page < 5:\n",
    "                print(\"######################page: {} ########################\".format(page))\n",
    "                print(\"Starting to get posts...\")\n",
    "                time.sleep(7)\n",
    "                details_posts = browser.find_elements_by_css_selector(\".ui_column.is-9\")\n",
    "                print(len(details_posts))\n",
    "                for content in details_posts:\n",
    "                    title = content.find_element_by_css_selector(\".quote\").text\n",
    "                    comment = content.find_element_by_css_selector(\".partial_entry\").text\n",
    "                    score_element = content.find_element_by_css_selector('div > span:first-child')\n",
    "                    class_name = score_element.get_attribute('class')\n",
    "                    score = int(re.search('\\d+',class_name).group()) // 10\n",
    "\n",
    "                    se = pd.Series([title,comment,score],index=['title','comment',\"score\"])\n",
    "                    details_df = details_df.append(se, ignore_index=True)\n",
    "                    print(se)\n",
    "                page+=1\n",
    "                browser.find_element_by_css_selector(\".nav.next.taLnk.ui_button.primary\").click()\n",
    "                time.sleep(7)\n",
    "                \n",
    "            details_df.to_csv(\"df.csv\", index=False)\n",
    "\n",
    "        except:\n",
    "            print(\"finished!!!!\")\n",
    "\n",
    "    #details_df= details_df.drop_duplicates()\n",
    "\n",
    "    return details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下関数は卒業発表時のもの\n",
    "#HPの構成が変わったようなので、動かない....\n",
    "# def get_details():\n",
    "#     details_df = pd.DataFrame()\n",
    "#     for i in range(len(df_url.index)): \n",
    "#         print(\"getting info of {}\".format(df_url.loc[i].url))\n",
    "#         browser = webdriver.Chrome(executable_path=\"/Users/shimizutakashibun/chromedriver\")\n",
    "#         browser.get(df_url.loc[i].url)\n",
    "#         page=0\n",
    "#         try:\n",
    "#             while page < 99:\n",
    "#                 print(\"######################page: {} ########################\".format(page))\n",
    "#                 print(\"Starting to get posts...\")\n",
    "#                 time.sleep(7)\n",
    "#                 details_posts = browser.find_elements_by_css_selector(\".ui_column.is-9\")\n",
    "#                 print(len(details_posts))\n",
    "#                 for content in details_posts:\n",
    "#                     title = content.find_element_by_css_selector(\".quote\").text\n",
    "#                     comment = content.find_element_by_css_selector(\".partial_entry\").text\n",
    "#                     score_content = content.find_element_by_xpath('//*[@id=\"review_667820115\"]/div/div[2]/span[1]').get_attribute('class')\n",
    "                    \n",
    "#                     se = pd.Series([title,comment,score_text],index=['title','comment',\"score_content\"])\n",
    "#                     details_df = details_df.append(se, ignore_index=True)\n",
    "#                     print(se)\n",
    "#                 details_df.to_csv(\"df.csv\", index=False)\n",
    "#                 page+=1\n",
    "#                 browser.find_element_by_css_selector(\".nav.next.taLnk.ui_button.primary\").click()\n",
    "#                 time.sleep(7)\n",
    "                \n",
    "#         except:\n",
    "#             print(\"finished!!!!\")\n",
    "\n",
    "#     details_df= details_df.drop_duplicates()\n",
    "\n",
    "#     return details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_details = get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_details = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態素解析\n",
    "### タイトルはコメントの要約に過ぎないので今回はコメントの分析だけ行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_analysis(text):\n",
    "    word_sequence = str()\n",
    "    try:\n",
    "        mecab = mc.Tagger('/usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "        \n",
    "        mecab.parse('')#文字列がGCされるのを防ぐ\n",
    "        node = mecab.parseToNode(text)  \n",
    "        \n",
    "        while node:\n",
    "            #単語を取得\n",
    "            word = node.surface\n",
    "            #品詞を取得\n",
    "            pos = node.feature.split(\",\")[1]\n",
    "            if pos in [\"一般\",\"固有名詞\",\"サ変接続\",\"形容詞\"]:\n",
    "                word_sequence = word_sequence + word+\" \"\n",
    "            #次の単語に進める\n",
    "            node = node.next\n",
    "        return word_sequence\n",
    "    except:\n",
    "        return word_sequence\n",
    "\n",
    "review_details[\"comment_mecab\"] = review_details[\"comment\"].apply(lambda x:mecab_analysis(x))\n",
    "#review_details[\"title_mecab\"] = review_details[\"title\"].apply(lambda x:mecab_analysis(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idfでベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_reviews = review_details[\"comment_mecab\"]\n",
    "reviews_vectorizer = TfidfVectorizer(use_idf=True,token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "reviews_vecs = reviews_vectorizer.fit_transform(tfidf_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_vecs_df = pd.DataFrame(reviews_vecs.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([review_details,reviews_vecs_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [\"comment\",\"title\",\"comment_mecab\"]\n",
    "for_reg_df = concat_df.drop(drop_col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_reg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "import matplotlib.pyplot as pyp\n",
    "from sklearn.linear_model import RidgeCV,LassoCV,ElasticNetCV,RidgeClassifierCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(for_reg_df.iloc[:,1:],for_reg_df[\"score\"], train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf = RidgeCV().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_clf = LassoCV(cv=10).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],'l1_ratio':[0.1,0.2,0.3,0.5,0.7,0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_grid = GridSearchCV(ElasticNet(),param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_clf = ElasticNet(alpha=0.1,l1_ratio=0.1).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred =ridge_clf.predict(x_val)\n",
    "lasso_pred=lasso_clf.predict(x_val)\n",
    "elastic_pred = elastic_clf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLassoでの係数\")\n",
    "print(lasso_clf.intercept_) \n",
    "print(lasso_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRidgeでの係数\")\n",
    "print(ridge_clf.intercept_) \n",
    "print(ridge_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nElasticNetでの係数\")\n",
    "print(elastic_clf.intercept_) \n",
    "print(elastic_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nridge_RMS\")\n",
    "ridge_RMS = np.mean((ridge_pred - y_val) **2)\n",
    "print(ridge_RMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nlasso_RMS\")\n",
    "lasso_RMS = np.mean((lasso_pred - y_val) **2)\n",
    "print(lasso_RMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nelasticnet_RMS\")\n",
    "elastic_RMS = np.mean((elastic_pred - y_val) **2)\n",
    "print(elastic_RMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 平均二乗誤差が小さいRidge回帰を採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(ridge_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(ridge_clf.coef_ > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(ridge_clf.coef_ > 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf.coef_[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf.coef_[1796]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#リストから参照する方法\n",
    "#https://qiita.com/supersaiakujin/items/d63c73bb7b5aac43898a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(ridge_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf.coef_[918]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(ridge_clf.coef_ < -0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='1416' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='108' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='756' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='1615' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='1784' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='1796' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='1960' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='2195' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(reviews_vectorizer.vocabulary_.items()))[np.array(list(reviews_vectorizer.vocabulary_.items()))[:,1]=='2836' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
